{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB-Sentiment Analysis Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/labeledTrainData.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_data_frame_from_file_path(file_path):\n",
    "\n",
    "    tsv_file = open(file_path, encoding='utf-8')\n",
    "    read_tsv = csv.reader(tsv_file, delimiter='\\t')\n",
    "    df_list = list()\n",
    "\n",
    "    for row in read_tsv:\n",
    "        df_list.append(row)\n",
    "    df = pd.DataFrame(df_list[1:], columns=df_list[0])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13762, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = obtain_data_frame_from_file_path(file_path)\n",
    "df.shape # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id sentiment                                             review\n",
       "0  5814_8         1  With all this stuff going down at the moment w...\n",
       "1  2381_9         1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3         0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4         0  It must be assumed that those who praised this...\n",
       "4  9495_8         1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6922\n",
       "0    6840\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.502979\n",
       "0    0.497021\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized value counts\n",
    "df.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two values are close to even, `sentiment` column can be considered **balanced**. In this case, **accuracy** is an appropiate metric to assess the quality of the model. Otherwise you could use **F1-score** for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plot the `sentiment` column value counts by calling the `plot()` function. The bar plot is quite informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sentiment.value_counts().plot(kind=\"bar\", color=[\"salmon\", \"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use `df.info()` to see if there were any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13762 entries, 0 to 13761\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         13762 non-null  object\n",
      " 1   sentiment  13762 non-null  object\n",
      " 2   review     13762 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 322.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install **bs4** (Beautiful Soup) library - which is used for remove HTML Tags.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install **gensim** library - which is used for advanced Natural Language Processing. In this case to remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from beautifulsoup4->bs4) (2.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from gensim) (0.29.14)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from gensim) (4.0.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\sorin\\project\\myenvironment\\lib\\site-packages (from gensim) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_html_tags(review_text):\n",
    "    soup = BeautifulSoup(review_text, 'html.parser')\n",
    "    return soup.get_text(separator=' ')\n",
    "\n",
    "\n",
    "def eliminate_special_characters(review_text):\n",
    "    pattern = r'[^a-zA-Z\\s]'\n",
    "    return re.sub(pattern, ' ', review_text)\n",
    "\n",
    "\n",
    "def preprocess_the_text(review_text):\n",
    "    review_text = eliminate_html_tags(review_text)\n",
    "    review_text = eliminate_special_characters(review_text)\n",
    "    review_text = review_text.lower()\n",
    "    review_text = remove_stopwords(review_text)\n",
    "    return review_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(preprocess_the_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vectorize review texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(lowercase=False, min_df=0.001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.001, lowercase=False)\n",
    "vectorizer.fit(df['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train two models: Logistic Regression and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['review'].values\n",
    "sentiments = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_ = 0.2\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, review_test, y_train, y_test = train_test_split(reviews,\n",
    "                                                                  sentiments,\n",
    "                                                                  test_size=test_size_,\n",
    "                                                                  random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(reviews_train)\n",
    "X_test = vectorizer.transform(review_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test, random_seed):\n",
    "\n",
    "    lr_classifier = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "    print(\"Train Logistic Regression model.\")\n",
    "    lr_classifier.fit(X_train, y_train)\n",
    "    score = lr_classifier.score(X_test, y_test)\n",
    "    print('Accuracy obtained by Logistic Regression: {:.2f}%'.format(score * 100))\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=200,\n",
    "                                           n_jobs=-1,\n",
    "                                           random_state=random_seed)\n",
    "    print(\"\\nTrain Random Forest Classifier model.\")\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    score = rf_classifier.score(X_test, y_test)\n",
    "    print('Accuracy obtained by Random Forest Classifier: {:.2f}%'.format(score * 100))\n",
    "\n",
    "    return (lr_classifier, rf_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sorin\\Project\\MyEnvironment\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained by Logistic Regression: 86.92%\n",
      "\n",
      "Train Random Forest Classifier model.\n",
      "Accuracy obtained by Random Forest Classifier: 84.96%\n"
     ]
    }
   ],
   "source": [
    "rf_model, lr_model = train_models(X_train, X_test,\n",
    "                                     y_train, y_test,\n",
    "                                     random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's that the Logistic Regression Model gives a slightly higer quality result than Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare the value of `Accuracy metric` accross two models using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cross_validation(X, y, model):\n",
    "\n",
    "    cv_ = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(model,\n",
    "                             X, y,\n",
    "                             scoring='accuracy',\n",
    "                             cv=cv_,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "    print(scores)\n",
    "    print('Accuracy obtained by Random Forest Classifier: {:.2f}%, ({:.4f})'.format(mean(scores)*100, std(scores)))\n",
    "\n",
    "    return mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(reviews)\n",
    "y = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Fold cross-validation for Logistic Regression model.\n",
      "[0.86923356 0.86705412 0.85901163 0.84593023 0.84665698]\n",
      "Accuracy obtained by Random Forest Classifier: 85.76%, (0.0098)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8575773046739709"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nK-Fold cross-validation for Logistic Regression model.\") \n",
    "apply_cross_validation(X, y, lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Fold cross-validation for Random Forest model.\n",
      "[0.8459862  0.84998184 0.83648256 0.83938953 0.83030523]\n",
      "Accuracy obtained by Random Forest Classifier: 84.04%, (0.0069)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8404290720904889"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nK-Fold cross-validation for Random Forest model.\")\n",
    "apply_cross_validation(X, y, rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the **Accuracy metric** accross two models using cross-validation is higher in the case of the **logistic regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find the optimal parameters for the model that performs better using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_optimal_parameters_using_GridSearch(X, y,\n",
    "                                                  model,\n",
    "                                                  param_grid_):\n",
    "    print(\"Grid Search\")\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                               param_grid=param_grid_,\n",
    "                               cv=5,\n",
    "                               scoring='accuracy',\n",
    "                               n_jobs=-1,\n",
    "                               verbose=2)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_model_accuracy = cross_val_score(best_model, X, y, scoring='accuracy').mean()\n",
    "    print('Accuracy obtained by best model: {:.2f}%'.format(best_model_accuracy * 100))\n",
    "\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "      'n_estimators': [100, 200, 500, 1000],\n",
    "      'max_features': ['auto', 'sqrt', 'log2'],\n",
    "      'max_depth': [10, 15, 20, 30, 50],\n",
    "      'criterion': ['gini', 'entropy']\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 22.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained by best model: 86.41%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_the_optimal_parameters_using_GridSearch(X, y, rf_model, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "      'penalty': ['l2', 'none'],\n",
    "      'tol': [1e-4, 1e-5, 1e-6],\n",
    "      'C': [0.01, 0.1, 1.0, 10],\n",
    "      'max_iter': [100, 200, 500]\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained by best model: 86.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_the_optimal_parameters_using_GridSearch(X, y, lr_model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the accuracy of the model you can try the following steps:\n",
    "- Stemming and Lemmatization, to reduce a word to its root form;\n",
    "- Try other parameters to find more optimal ones using Grid Search CV;\n",
    "- Try Random Search CV;\n",
    "- Try another models like: Deep Learning, SVM, Naive Bayes and other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
